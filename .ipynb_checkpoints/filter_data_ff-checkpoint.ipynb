{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This file aims to do pre-processing to get bug features. The difference with 'filter_data.ipynb' is that is that it uses more fields \n",
    "# of the bugs. I process the bugs assigned to CPD platform team and store them in the table 'bugs_cpdplatform_ff' with 'ff' meaning\n",
    "# 'full fields'\n",
    "import MySQLdb\n",
    "import pandas\n",
    "import re\n",
    "import itertools\n",
    "import nltk\n",
    "# from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# conn = MySQLdb.connect(host='10.117.8.41', port=3306, user='root', passwd='vmware', db='bugdata')\n",
    "# cur =conn.cursor()\n",
    "# sql = '''SELECT bug_id, thetext\n",
    "# FROM longdescs\n",
    "# WHERE bug_id = 943195'''\n",
    "# cur.execute(sql)\n",
    "# temp = cur.fetchall()\n",
    "# for item in temp:\n",
    "#     print len(item[1])\n",
    "# print temp[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove cites in a comment\n",
    "def rm_cite(raw_text):\n",
    "    lst = []\n",
    "    iscite = False\n",
    "    lines = raw_text.splitlines()\n",
    "    for idx,line in enumerate(lines):\n",
    "        if line.startswith(\"(In reply to comment\"):\n",
    "            iscite = True\n",
    "            lst.append(idx)\n",
    "        elif line.startswith(\">\"):\n",
    "            if iscite == True:\n",
    "                lst.append(idx)\n",
    "        else:\n",
    "            iscite = False\n",
    "        \n",
    "    return '\\n'.join([item[1] for item in filter(lambda x: x[0] not in lst, enumerate(lines))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "def preprocess_strict( raw_description, output):\n",
    "    # Function to convert a raw bug description to a list of words or a cleared string, it's \"strict\" in the sense that it removes all non-letters \n",
    "    # Remove markers\n",
    "    # text = BeautifulSoup(raw_description).get_text() \n",
    "    \n",
    "    # Remove cites\n",
    "    description = rm_cite(raw_description)\n",
    "    \n",
    "    # Remove urls\n",
    "    text = re.sub(\"((mailto\\:|(news|(ht|f)tp(s?))\\://){1}\\S+)\", \" \", description)\n",
    "    \n",
    "    # Remove non-letters        \n",
    "    # letters_only = re.sub(\"[^a-zA-Z_/\\-\\.]\", \" \", description_text)\n",
    "    letters_only = re.sub(\"[^a-zA-Z\\.]\", \" \", text)\n",
    "    letters_only = re.sub(\"\\.(?!((c|h|cpp|py)\\s+$))\", \" \", letters_only)\n",
    "    \n",
    "    # Convert to lower case, tokenize\n",
    "    words = [word for sent in nltk.sent_tokenize(letters_only.lower()) for word in nltk.word_tokenize(sent)]\n",
    "    \n",
    "    # Remove stop words\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    meaningful_words = [w for w in words if not w in stopwords]\n",
    "    \n",
    "    # Stemming\n",
    "    snowball = SnowballStemmer(\"english\")\n",
    "    stems = [snowball.stem(w) for w in meaningful_words]\n",
    "    \n",
    "    if output == \"list\":\n",
    "        return stems\n",
    "    else:\n",
    "        return \" \".join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_mild( raw_description, output):\n",
    "    # Function to convert a raw bug description to a list of words or a cleared string, it's \"mild\" in the sense that it removes words that don't contain letters\n",
    "    # Remove markers\n",
    "    # text = BeautifulSoup(raw_description).get_text() \n",
    "    \n",
    "    # Remove cites\n",
    "    description = rm_cite(raw_description)\n",
    "    \n",
    "    # Remove urls\n",
    "    text = re.sub(\"((mailto\\:|(news|(ht|f)tp(s?))\\://){1}\\S+)\", \" \", description)\n",
    "    text = re.sub(\"[^\\x00-\\x7f]\", \" \", text)\n",
    "    \n",
    "    # Convert to lower case, tokenize\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    \n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    meaningful_tokens = [token for token in filtered_tokens if not token in stopwords]\n",
    "    \n",
    "    # Stemming\n",
    "    snowball = SnowballStemmer(\"english\")\n",
    "    stems = [snowball.stem(t) for t in meaningful_tokens]\n",
    "    \n",
    "    if output == \"list\":\n",
    "        return stems\n",
    "    else:\n",
    "        return \" \".join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn_data = MySQLdb.connect(host='10.117.8.41', port=3306, user='root', passwd='vmware', db='bugdata')\n",
    "cur_data =conn_data.cursor()\n",
    "\n",
    "sql = '''SELECT bug_id, assigned_to, short_desc, host_op_sys, guest_op_sys, priority, product_id, category_id, component_id, found_in_product_id, found_in_version_id, found_in_phase_id, cf_security\n",
    "FROM bugs,profiles \n",
    "WHERE bugs.assigned_to=profiles.userid and profiles.login_name in ('hfu','letian','vbhakta','weili','nmukuri','zhoum','hxie','shiyaoy','shanpeic','souravk','vaibhavk','fangchiw','gengshengl')'''\n",
    "\n",
    "cur_data.execute(sql)\n",
    "bugs_cpdplatf = cur_data.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "bugdata = []\n",
    "\n",
    "conn_data = MySQLdb.connect(host='10.117.8.41', port=3306, user='root', passwd='vmware', db='bugdata')\n",
    "cur_data =conn_data.cursor()\n",
    "\n",
    "for item in bugs_cpdplatf:\n",
    "    sql_ld = '''SELECT bug_id, thetext\n",
    "    FROM longdescs\n",
    "    WHERE bug_id = (%s)''' % str(item[0])\n",
    "    \n",
    "    df = pandas.io.sql.read_sql(sql_ld, conn_data)\n",
    "    \n",
    "    keywords = preprocess_strict(item[2],\"list\")\n",
    "    \n",
    "    text = list(df['thetext'].map(lambda x: preprocess_mild(x,\"list\")))\n",
    "    \n",
    "    # judge if a comment is a technical comment, the standard is that the length is bigger than 10 and it has some keywords (which is extracted from the 'short_desc' of \n",
    "    # the same bug) or the length is bigger than 30\n",
    "    def judge(wordlist):       \n",
    "        if (len(wordlist) > 10 and len(set(keywords) & set(wordlist)) > 0 ) or len(wordlist) > 30:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    long_desc = list(itertools.chain(*filter(judge, text)))\n",
    "    \n",
    "    sql_ni = '''SELECT bug_id, who\n",
    "    FROM needinfo\n",
    "    WHERE bug_id = (%s)''' % str(item[0])\n",
    "    \n",
    "    df = pandas.io.sql.read_sql(sql_ni, conn_data)\n",
    "    \n",
    "    needinfo = list(df['who'].map(str))\n",
    "    \n",
    "    bugdata.append((str(item[0]), str(item[1]), item[2], item[3], item[4], item[5], str(item[6]), str(item[7]), str(item[8]), str(item[9]), str(item[10]), str(item[11]), str(item[12]), \" \".join(needinfo), \" \".join(keywords), \" \".join(long_desc)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn_feature = MySQLdb.connect(host='10.117.8.41', port=3306, user='root', passwd='vmware', db='bugfeature')\n",
    "cur_feature =conn_feature.cursor()\n",
    "\n",
    "sql_ins = '''INSERT into bugs_cpdplatform_ff\n",
    "VAlUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "    \n",
    "cur_feature.executemany(sql_ins,bugdata)\n",
    "conn_feature.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['19367']\n",
      "    bug_id    who\n",
      "0  1285973  19367\n"
     ]
    }
   ],
   "source": [
    "conn_data = MySQLdb.connect(host='10.117.8.41', port=3306, user='root', passwd='vmware', db='bugdata')\n",
    "cur_data =conn_data.cursor()\n",
    "\n",
    "sql_ni = '''SELECT bug_id, who\n",
    "FROM needinfo\n",
    "WHERE bug_id = 1285973'''\n",
    "\n",
    "df = pandas.io.sql.read_sql(sql_ni, conn_data)\n",
    "    \n",
    "needinfo = list(df['who'].map(str))\n",
    "\n",
    "print needinfo\n",
    "print df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
